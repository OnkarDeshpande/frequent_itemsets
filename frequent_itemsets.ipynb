{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'kosarak.dat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read into list of sets\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename, no_lines = 10000):\n",
    "    l = []\n",
    "    count = 0\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            l.append(set([int(ele) for ele in line.replace('\\n','').split()]))\n",
    "            count+=1\n",
    "            if count > no_lines:\n",
    "                print('Data read into list of sets')\n",
    "                break\n",
    "    \n",
    "    return l\n",
    "basket_data = load_data(filename)\n",
    "# basket_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prod_list(data):\n",
    "    prod_list = []\n",
    "    for basket in data:\n",
    "        for prod in basket:\n",
    "            if prod not in prod_list:\n",
    "                prod_list.append([prod])\n",
    "    print('Product list created!')\n",
    "    return list(map(frozenset,prod_list))\n",
    "\n",
    "# c1 = create_prod_list(basket_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lk(dataset, ck, threshold=0.01*10000):\n",
    "    freq_count = {}\n",
    "    for basket in dataset:\n",
    "        for pair in ck:\n",
    "            if pair.issubset(basket):\n",
    "                if pair in freq_count:\n",
    "                    freq_count[pair]+=1\n",
    "                else:\n",
    "                    freq_count[pair]=1\n",
    "    \n",
    "    data_size = len(dataset)\n",
    "    sort_count = sorted(freq_count.items(), key=lambda x:x[1], reverse = True)\n",
    "    lk = []\n",
    "    support_dict = {}\n",
    "    for ele in sort_count:\n",
    "        if ele[1] > threshold:\n",
    "            lk.append(ele[0])\n",
    "            support_dict[ele[0]] = ele[1]/data_size\n",
    "    print(\"Created L set\")\n",
    "    lk.sort()\n",
    "    return lk, dict(sort_count)\n",
    "    \n",
    "# l1, supp_dict = create_lk(basket_data, c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.01*count\n",
    "\n",
    "# list(l1[5])[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ck(lk,k):\n",
    "    retList = []\n",
    "    lenlk = len(lk)\n",
    "    for i in range(lenlk):\n",
    "        for j in range(i+1, lenlk): \n",
    "            tmp_l1 = list(lk[i])[:k-2]\n",
    "            tmp_l2 = list(lk[j])[:k-2]\n",
    "            if tmp_l1==tmp_l2: #if first k-1 elements are equal\n",
    "                retList.append(lk[i] | lk[j]) #set union\n",
    "    print(\"Created C set\")\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(data, threshold=0.01*10000):\n",
    "    print(\"Start Apriori algorithm\")\n",
    "    c1 = create_prod_list(data)\n",
    "    l1, support_data = create_lk(data, c1)\n",
    "    L = [l1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        print(\"Value for K:\"+str(k))\n",
    "        ck = create_ck(L[k-2], k)\n",
    "        Lk, supK = create_lk(data, ck, threshold)#scan DB to get Lk\n",
    "        support_data.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, support_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Apriori algorithm\n",
      "Product list created!\n",
      "Created L set\n",
      "Value for K:2\n",
      "Created C set\n",
      "Created L set\n",
      "Value for K:3\n",
      "Created C set\n",
      "Created L set\n",
      "Value for K:4\n"
     ]
    }
   ],
   "source": [
    "sets, support_info = apriori(basket_data, threshold=0.001*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conf(itemset, H, support_data, rl, conf=0.7):\n",
    "    prunedH = [] #create new list to return\n",
    "    for conseq in H:\n",
    "        tmp_conf = support_data[itemset]/support_data[itemset-conseq] #calc confidence\n",
    "        if tmp_conf >= conf: \n",
    "            print (itemset-conseq,'-->',conseq,'conf:',tmp_conf)\n",
    "            rl.append((itemset-conseq, conseq, tmp_conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesFromConseq(itemset, H, support_data, rl, conf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):    #try further merging\n",
    "        Hmp1 = create_ck(H, m+1)     #create Hm+1 new candidates\n",
    "        Hmp1 = calculate_conf(itemset, Hmp1, support_data, rl, conf)\n",
    "        if (len(Hmp1) > 1):    #need at least two sets to merge\n",
    "            rulesFromConseq(itemset, Hmp1, support_data, rl, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(frequent_itemsets, support_data, conf=0.7):  #supportData is a dict coming from scanD\n",
    "    rule_list = []\n",
    "    for i in range(1, len(frequent_itemsets)):#only get the sets with two or more items\n",
    "        for itemset in frequent_itemsets[i]:\n",
    "            H1 = [frozenset([item]) for item in itemset]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(itemset, H1, support_data, rule_list, minConf)\n",
    "            else:\n",
    "                calculate_conf(itemset, H1, support_data, rule_list, minConf)\n",
    "    return rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for item in ordered_map:\n",
    "    if item[1]>=threshold:\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "ordered_map = ordered_map[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = dict(ordered_map)\n",
    "# c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_count2 = {}\n",
    "for item in l:\n",
    "    tmp = [ele for ele in item if ele in c1]\n",
    "    tmp.sort()\n",
    "    if tmp and len(tmp)>1:\n",
    "        for i in range(len(tmp)-1):\n",
    "            for j in range(i+1,len(tmp)):\n",
    "                if tmp[i] in item and tmp[j] in item:\n",
    "                    if str(tmp[i])+\"_\"+str(tmp[j]) in freq_count2:\n",
    "                        freq_count2[str(tmp[i])+\"_\"+str(tmp[j])]+=1\n",
    "                    else:\n",
    "                        freq_count2[str(tmp[i])+\"_\"+str(tmp[j])] = 1\n",
    "                        c2\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = sorted(freq_count2.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = [ele for ele in c2 if ele[1]> threshold]\n",
    "c2 = dict(c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_count3 = {}\n",
    "for item in l:\n",
    "    tmp = [ele for ele in item if ele in c1]\n",
    "    tmp.sort()\n",
    "    if tmp and len(tmp)>1:\n",
    "        for i in range(len(tmp)-1):\n",
    "            for j in range(i+1,len(tmp)):\n",
    "                if tmp[i] in item and tmp[j] in item:\n",
    "                    if str(tmp[i])+\"_\"+str(tmp[j]) in freq_count2:\n",
    "                        freq_count2[str(tmp[i])+\"_\"+str(tmp[j])]+=1\n",
    "                    else:\n",
    "                        freq_count2[str(tmp[i])+\"_\"+str(tmp[j])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
